import asyncio
from doctest import UnexpectedException
import json
import logging
from re import L
from shutil import ExecError
from typing import Awaitable, Dict, List, Any, Optional, Tuple, Union, Callable, Literal
import httpx
from langchain_core.runnables import RunnableLambda
from langgraph.graph import StateGraph, END
import traceback
# from langgraph.prebuilt import ToolNode
# from langgraph.graph.message import add_messages
from langgraph.graph.graph import CompiledGraph
from langchain_core.messages import HumanMessage, AIMessage
from browser_use import ActionResult, AgentHistoryList
# from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from Utils.prompts import (
    FILLER_PROMPT,
    THINKER_PROMPT,
    EXEPROMPT,
)
from Utils.structured_llm import StructuredLLMHandler
from Utils.routing_module import InternalState, Router, RouteConfig
from Utils.schemas import (
    Task, 
    ResearchResult
)
from textwrap import dedent
from .Browser_Agent import BrowserAgentHandler
# Configure logging
logging.basicConfig(level=logging.ERROR, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("AutoAgent")


VALIDATION_PROMPT = dedent("""
You are a Validator Agent with the following responsibility: after the main browser agent has executed a user-requested task, you must verify whether the task has been completed successfully. You will be provided with two inputs: the original {user_task} and the {agent_response} generated by the browser agent.

Your tasks are as follows:

1. Analyze the provided use task and fully understand its objectives.
2. Evaluate the agent response against the criteria defined by the user task.
   - If the response completely meets the user task requirements, set "user_task_completed" to True.
   - If any requirement is missing or an error occurred, set "user_task_completed" to False.
3. If the task is not fully completed:
   a. Identify the reason for the failure as indicated in the agent response.
   b. Generate a revised and precise instruction for the browser agent that addresses the error and re-aligns with the original user task.
   c. Return this new instruction in the "next_step" field.
4. If the task is successfully completed:
   a. Return the final output (as determined from the agent response) in the "final_response" field.
   b. Keep the "next_step" field as None.
5. Your output must strictly adhere to the following pydantic model structure:
{{
    "user_task_completed" : bool = <True if task is completed else False.>
    "next_step" : Optional[str] = <Next new task>
    "final_response": Optional[str] = <the final response>
}}

The user task is:
{user_task}
The agent response is:
{agent_response} 
""")

class ThinkerOutputStruct(BaseModel):
    """Pydantic model for the task analyzer response."""
    
    task_type: Literal["OTHER", "FORM", "RESEARCH"] = Field(
        description="Type of task: FORM for web form filling actions, RESEARCH for information gathering tasks, OTHER for any other simple action type of task.",
    )
    
    refined_task: str = Field(
        description="Enhanced version of the original task with all implicit actions made explicit",
        min_length=10,
        max_length=500
    )
    
    constraints: List[str] = Field(
        description="Any limitations or special considerations the agent should be aware of",
        default_factory=list,
        min_items=1  # Ensure at least one constraint is provided
    )

    
class FormStructuredOutput(BaseModel):
    need_more_info: bool = Field(
        default=False, 
        description="Indicates whether additional information is required (True) or not (False)."
    )
    required_info: str = Field(
        default=None,
        description="If need_more_info is True, this dictionary lists the specific form fields for which user information is missing."
    )
    json_output: str = Field(
        default=None,
        description="This dictionary contains the final structured form data filled with the user's information."
    )

class ExeActionStruct(BaseModel):
    user_task_completed : bool
    next_step : Optional[str] = None
    final_response : Optional[str] = None


class ProcessContext(BaseModel):
    process_history : List[str] = Field(default_factory=list)
    next_step : Optional[str] = None
    
class AutoAgentState(BaseModel):
    """State model for AutoAgent"""
    user_task: str
    routes: Dict[str,List[str]] = Field(default_factory=dict)
    route_config : Dict[str,RouteConfig] =Field(default_factory=dict)
    sensitive_data : Optional[Dict] = None
    research_results: List[str] = Field(default_factory=list)
    tasks: List[Task] = Field(default_factory=list)
    messages: List[Union[HumanMessage, AIMessage]] = Field(default_factory=list)
    context_id : str
    results : Dict[str,Any] = Field(default_factory=dict)
    # errors = "This is the error"
    # send_list : Dict[str, List[InternalState]] = Field(default_factory=dict)
    # step : int = Field(default=0)
    # question : Optional[str] = None
    # process_context : ProcessContext = None
    # input : Dict[str,str] = Field(default_factory=dict)

class AutoAgent:
    """
    AutoAgent class for automating web tasks through prompting.
    Uses a Langgraph-based workflow to research, validate, and execute tasks.
    """
    
    def __init__(
        self,
        llm_dict :Dict[str,Any],
        fallback_llm : str = None,
        browser_agent : BrowserAgentHandler = None,
        max_steps : int = 10,
        search_api_key: Optional[str] = None,
        search_engine: str = "duckduckgo",
        max_search_results: int = 10,
        timeout: int = 30,
        max_retries: int = 3,
        verbose: bool = False,
    ):
        """
        Initialize the AutoAgent class.
        
        Args:
            llm: Language model to use for thinking and task generation
            search_api_key: API key for search engine
            search_engine: Search engine to use (duckduckgo or tavily)
            max_search_results: Maximum number of search results to process
            timeout: Timeout for API calls in seconds
            max_retries: Maximum number of retries for API calls
            verbose: Whether to log detailed information
        """
        self._llm_dict = llm_dict
        self._fallback_llm = fallback_llm 
        self.search_api_key = search_api_key
        self.search_engine = search_engine
        self.max_search_results = max_search_results
        self.timeout = timeout
        self.max_retries = max_retries
        self.verbose = verbose
        self._max_steps = max_steps
        self.LLMHandler = StructuredLLMHandler(llm_dict=llm_dict, 
                                               fallback_llm=fallback_llm)
        self._Router :Router = Router(name = "autoagent")
        # Initialize HTTP client for API calls
        self.http_client = httpx.AsyncClient(timeout=timeout)
        self.BrowserAgent = browser_agent or BrowserAgentHandler(llm_dict=llm_dict)
        # Set up the workflow graph
        self.workflow :CompiledGraph = self._build_workflow()
        
    def _build_workflow(self) -> StateGraph:
        """Build the workflow graph for the agent."""
        
        # Define the nodes
        workflow = StateGraph(AutoAgentState)
        
        # Add nodes
        workflow.add_node("thinker", self.thinker_node)
        workflow.add_node("researcher", self.researcher_node)
        workflow.add_node("other", self.other_node)
        workflow.add_node("human_input", self.human_node)
        workflow.add_node("form_filler", self.form_node)
        
        # Define edges
        workflow.add_conditional_edges("thinker", self._Router.get_routing_function("thinker"))
        workflow.add_conditional_edges("other", self._Router.get_routing_function("other"))
        
        # Set the entry point
        workflow.set_entry_point("thinker")
        
        # Compile the workflow
        return workflow.compile()
    
    async def thinker_node(self, state: AutoAgentState) -> AutoAgentState:
        """
        Consider the query and determine if research is needed or if the task is basic.
        
        Args:
            state: Current state of the agent
            
        Returns:
            Updated state with thinking results
        """

        try:
            user_task  = state.user_task
            response : ThinkerOutputStruct = await self.LLMHandler.get_structured_response(
                    prompt=THINKER_PROMPT, 
                    output_structure=ThinkerOutputStruct,
                    user_task = user_task,
                )
            task_type = response.task_type
            
            if task_type == "OTHER":

                state.routes["thinker"] = ["other"]
                state.route_config["thinker"] = RouteConfig(
                    from_node="thinker",
                    conditional_nodes=["other"]
                )
                    
            elif task_type == "FORM":

                state.routes["thinker"] = ["form_filler"]
                state.route_config["thinker"] = RouteConfig(
                    from_node="thinker",
                    conditional_nodes=["form_filler"])
                
                
            elif task_type == "RESEARCH":

                state.routes["thinker"] = ["researcher"]
                state.route_config["thinker"] = RouteConfig(
                    from_node="thinker",
                    conditional_nodes=["researcher"]
                )

            else:
                raise UnexpectedException("Got no thoughts and task from the Thinker node response:")
            
            state.tasks.append(
                    Task(
                        task_description= response.refined_task,
                        constraints = response.constraints
                    )
                )
            return state
            
        except Exception as e:
            error_msg = f"Error in thinker_node: {str(e)}"
            logger.error(error_msg)
            raise e
    
    async def form_node(self, state : AutoAgentState) -> AutoAgentState:
        USER_INFO = {
                    "10" : {
                        "username" : "Aman Singh",
                        "user_phone_number" : "+91-8083343",
                        "user_email" : "amanragu2002@gmail.com",
                        "gender" : "male",
                        "preference" : {
                            "language" : ["English", "Hindi"]
                        },
                        "extra_info" : [ "years of experience: 2", 
                        "Skills : API testing ", 
                        "QA Tools : selenium ",
                        "Current Address : 282, adv colony, jaipur", 
                        "Password : 0837083",
                        "Other Details : thank you"
                        ]
                    }
                }
        failures = 0
        max_failures = 3
        context_id = state.context_id
        new_task = None
        try:
            response_history : AgentHistoryList = await self.BrowserAgent.run_task(
                            context_id=context_id,
                            task = str(state.tasks[-1]),
                            use_vision=True)
  
            action : FormStructuredOutput = await self.LLMHandler.get_structured_response(
                prompt = FILLER_PROMPT,
                output_structure= FormStructuredOutput,
                agent_response = response_history.extracted_content(),
                user_info = USER_INFO
            )
            info = 1
            if action.need_more_info:
                user_input = input(f"Can you please provide information about : {action.required_info} :: ")
                USER_INFO[f"extra_info_{info}"] = [action.required_info, user_input]
                
            else:
                while True and failures<=max_failures:
                    browser_response : AgentHistoryList = await self.BrowserAgent.run_task(
                                context_id = context_id,
                                task = f"The task is to fill the provided information in the current form {action.json_output}",
                                )
                    
                    
                    next_action : ExeActionStruct = await self.LLMHandler.get_structured_response(
                            output_structure=ExeActionStruct,
                            prompt = VALIDATION_PROMPT,
                            user_task = state.user_task,
                            agent_response = browser_response.final_result(),
                        )
                        
                    if next_action.user_task_completed:
                            print("Task is completed!!!")
                            state.routes["form_filler"] = [END]
                            state.route_config["form_filler"] = RouteConfig(
                                        from_node="form_filler",
                                        conditional_nodes=[END])
                            return state   
                        
                    else:
                            failures += 1
                            new_task = next_action.next_step
                            continue
                            
                
        except Exception as e:
                        print("error while executing agent Browser.")
                        print(e)
                        raise e
                    
        state.routes["form_filler"] = [END]
        state.route_config["form_filler"] = RouteConfig(
                    from_node="form_filler",
                    conditional_nodes=[END])
        
        return state
        
    async def researcher_node(self, state: AutoAgentState) -> AutoAgentState:
        """
        Perform web research based on the thinking results.
        
        Args:
            state: Current state of the agent
            
        Returns:
            Updated state with research results
        """
        logger.info("Starting research based on thoughts")
        return state
        # if not state.thoughts:
        #     state.errors.append("No thoughts provided for research")
        #     return state
        
        # try:
        #     # Extract search queries from thoughts
        #     system_prompt = """
        #     Based on the following thought about a user query, extract specific search queries that would help find the most relevant information. 
        #     Return ONLY the search queries as a JSON list of strings, with no additional text. Example:
        #     ["startup funding applications 2025", "open startup funding forms"]
        #     """
            
        #     messages = [
        #         {"role": "system", "content": system_prompt},
        #         {"role": "user", "content": f"Thought: {state.thoughts[-1]}"}
        #     ]
            
        #     response = await self.llm.ainvoke(messages)
        #     search_queries_text = response.content
            
        #     # Extract the JSON part
        #     try:
        #         # Find the JSON array in the response
        #         json_start = search_queries_text.find("[")
        #         json_end = search_queries_text.rfind("]") + 1
                
        #         if json_start >= 0 and json_end > json_start:
        #             search_queries_json = search_queries_text[json_start:json_end]
        #             search_queries = json.loads(search_queries_json)
        #         else:
        #             # Fallback: try to parse the entire response as JSON
        #             search_queries = json.loads(search_queries_text)
                
        #         if not isinstance(search_queries, list):
        #             search_queries = [str(search_queries)]
        #     except json.JSONDecodeError:
        #         # If JSON parsing fails, use a simple string splitting approach
        #         search_queries = [q.strip(' "\'') for q in search_queries_text.split(',')]
                
        #     # Execute the search for each query
        #     all_results = []
        #     for query in search_queries:
        #         results = await self._execute_search(query)
        #         all_results.extend(results)
            
        #     # Remove duplicates based on URL
        #     unique_results = []
        #     seen_urls = set()
        #     for result in all_results:
        #         if result.url not in seen_urls:
        #             seen_urls.add(result.url)
        #             unique_results.append(result)
            
        #     # Sort by relevance score
        #     unique_results.sort(key=lambda x: x.relevance_score, reverse=True)
            
        #     # Limit to max_search_results
        #     state.research_results = unique_results[:self.max_search_results]
            
        #     # Log results if verbose
        #     if self.verbose:
        #         logger.info(f"Found {len(state.research_results)} unique research results")
            
        #     return state
            
        # except Exception as e:
        #     error_msg = f"Error in researcher_node: {str(e)}"
        #     logger.error(error_msg)
        #     state.errors.append(error_msg)
        #     return state
    
    async def _execute_search(self, query: str) -> List[ResearchResult]:
        """
        Execute a search query using the configured search engine.
        
        Args:
            query: Search query string
            
        Returns:
            List of search results
        """
        results = []
        
        try:
            if self.search_engine == "duckduckgo":
                results = await self._search_duckduckgo(query)
            elif self.search_engine == "tavily":
                results = await self._search_tavily(query)
            else:
                raise ValueError(f"Unsupported search engine: {self.search_engine}")
                
            # Log search results if verbose
            if self.verbose:
                logger.info(f"Search for '{query}' returned {len(results)} results")
                
            return results
            
        except Exception as e:
            logger.error(f"Error executing search for '{query}': {str(e)}")
            return []
    
    async def _search_duckduckgo(self, query: str) -> List[ResearchResult]:
        """
        Search using DuckDuckGo.
        
        Args:
            query: Search query string
            
        Returns:
            List of search results
        """
        # Simulate DuckDuckGo search using a free API
        # Note: In a production environment, you'd use a proper DuckDuckGo API or integration
        url = "https://api.duckduckgo.com/"
        
        for attempt in range(self.max_retries):
            try:
                response = await self.http_client.get(
                    url,
                    params={"q": query, "format": "json", "no_html": "1", "no_redirect": "1"}
                )
                
                if response.status_code == 200:
                    data = response.json()
                    results = []
                    
                    # Process results from DuckDuckGo
                    for i, abstract in enumerate(data.get("AbstractText", [])):
                        results.append(
                            ResearchResult(
                                url=data.get("AbstractURL", f"https://example.com/result/{i}"),
                                title=data.get("Heading", f"Result {i}"),
                                description=abstract,
                                relevance_score=0.9 - (i * 0.05)  # Simple relevance score based on position
                            )
                        )
                    
                    # Also add results from the "RelatedTopics" if available
                    for i, topic in enumerate(data.get("RelatedTopics", [])):
                        if isinstance(topic, dict) and "Text" in topic and "FirstURL" in topic:
                            results.append(
                                ResearchResult(
                                    url=topic["FirstURL"],
                                    title=topic.get("Result", f"Related Result {i}"),
                                    description=topic["Text"],
                                    relevance_score=0.8 - (i * 0.03)
                                )
                            )
                    
                    return results
                
                # Handle rate limiting
                if response.status_code == 429:
                    wait_time = min(2 ** attempt, 60)  # Exponential backoff
                    logger.warning(f"Rate limited by DuckDuckGo API. Retrying in {wait_time} seconds.")
                    await asyncio.sleep(wait_time)
                    continue
                    
                logger.warning(f"DuckDuckGo search failed with status code {response.status_code}")
                return []
                
            except Exception as e:
                logger.error(f"Error in DuckDuckGo search: {str(e)}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(1)  # Wait a bit before retrying
                
        return []  # Return empty list if all attempts failed
    
    async def _search_tavily(self, query: str) -> List[ResearchResult]:
        """
        Search using Tavily API.
        
        Args:
            query: Search query string
            
        Returns:
            List of search results
        """
        if not self.search_api_key:
            logger.warning("No Tavily API key provided, cannot perform search")
            return []
            
        url = "https://api.tavily.com/search"
        headers = {
            "Authorization": f"Bearer {self.search_api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "query": query,
            "max_results": self.max_search_results,
            "search_depth": "advanced"
        }
        
        for attempt in range(self.max_retries):
            try:
                response = await self.http_client.post(url, headers=headers, json=payload)
                
                if response.status_code == 200:
                    data = response.json()
                    results = []
                    
                    for i, result in enumerate(data.get("results", [])):
                        results.append(
                            ResearchResult(
                                url=result.get("url", ""),
                                title=result.get("title", f"Result {i}"),
                                description=result.get("content", "No description"),
                                relevance_score=result.get("relevance_score", 0.9 - (i * 0.05))
                            )
                        )
                        
                    return results
                    
                # Handle rate limiting    
                if response.status_code == 429:
                    wait_time = min(2 ** attempt, 60)  # Exponential backoff
                    logger.warning(f"Rate limited by Tavily API. Retrying in {wait_time} seconds.")
                    await asyncio.sleep(wait_time)
                    continue
                
                logger.warning(f"Tavily search failed with status code {response.status_code}")
                return []
                
            except Exception as e:
                logger.error(f"Error in Tavily search: {str(e)}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(1)  # Wait a bit before retrying
                
        return []  # Return empty list if all attempts failed
    
    async def validator_node(self, state: AutoAgentState) -> AutoAgentState:
        """
        Validate the research results and create tasks for execution.
        
        Args:
            state: Current state of the agent
            
        Returns:
            Updated state with validated tasks
        """
        logger.info("Validating research results and creating tasks")
        
        if not state.research_results:
            state.errors.append("No research results to validate")
            return state
            
        try:
            # Format research results for LLM consumption
            research_results_str = "\n".join([
                f"URL: {result.url}\nTitle: {result.title}\nDescription: {result.description}\n"
                for result in state.research_results
            ])
            
            system_prompt = """
            You are an expert at validating web search results and creating actionable tasks.
            Review the research results and create specific tasks to execute on the most relevant websites.
            
            For each website that seems relevant to the query, create a task with:
            1. The website URL
            2. A clear description of what should be done on that website
            3. Any validation rules to ensure the task is completed correctly
            
            Return your answer as a JSON array of tasks with this format:
            [
                {
                    "website": "https://example.com",
                    "task_description": "Navigate to the funding application page and fill out the form with startup information",
                    "priority": "high|medium|low",
                    "validation_rules": ["Check if form submission was successful", "Verify confirmation message"]
                }
            ]
            
            Only include websites that are truly relevant to the query. Limit to the 5 most promising websites.
            """
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Query: {state.query}\n\nResearch Results:\n{research_results_str}"}
            ]
            
            response = await self.llm.ainvoke(messages)
            tasks_text = response.content
            
            # Extract tasks from response
            try:
                # Find the JSON array in the response
                json_start = tasks_text.find("[")
                json_end = tasks_text.rfind("]") + 1
                
                if json_start >= 0 and json_end > json_start:
                    tasks_json = tasks_text[json_start:json_end]
                    tasks_data = json.loads(tasks_json)
                else:
                    # Fallback: try to parse the entire response as JSON
                    tasks_data = json.loads(tasks_text)
                
                # Convert to Task objects
                tasks = []
                for task_data in tasks_data:
                    priority = TaskPriority.MEDIUM  # Default
                    
                    # Parse priority if present
                    if "priority" in task_data:
                        priority_str = task_data["priority"].lower()
                        if priority_str == "high":
                            priority = TaskPriority.HIGH
                        elif priority_str == "low":
                            priority = TaskPriority.LOW
                    
                    task = Task(
                        website=task_data["website"],
                        task_description=task_data["task_description"],
                        priority=priority,
                        validation_rules=task_data.get("validation_rules", [])
                    )
                    tasks.append(task)
                
                # Sort tasks by priority
                tasks.sort(key=lambda x: {
                    TaskPriority.HIGH: 0,
                    TaskPriority.MEDIUM: 1,
                    TaskPriority.LOW: 2
                }[x.priority])
                
                state.tasks = tasks
                
                # Log results if verbose
                if self.verbose:
                    logger.info(f"Created {len(state.tasks)} tasks from research results")
                
                return state
            
            except json.JSONDecodeError as e:
                error_msg = f"Error parsing tasks JSON: {str(e)}. Raw response: {tasks_text}"
                logger.error(error_msg)
                state.errors.append(error_msg)
                return state
                
        except Exception as e:
            error_msg = f"Error in validator_node: {str(e)}"
            logger.error(error_msg)
            state.errors.append(error_msg)
            return state
    
    async def human_node(self, state: AutoAgentState):
        logger.info("Now taking user input")
        waiting = state.waiting
        step = state.step
        if waiting and step < self._loop_steps:
            logger.info(f"The question is : {state.question}")
            logger.info(f"The next step is :{state.process_context.next_step}")
            await asyncio.sleep(10)
        
        state.input["username"] = "amanragu200@gmail.com"
        return state
        
    async def other_node(self, state: AutoAgentState) -> AutoAgentState:
        """
        Execute the validated tasks using the browser agent.
        
        Args:
            state: Current state of the agent
            
        Returns:
            Updated state with execution results
        """
        logger.info("Executing validated tasks")
        
        context_id = state.context_id
        task =  str({"task_description" :state.tasks[-1].task_description,
                 "constraints" : state.tasks[-1].constraints})
        print(task)
        sensitive_data = state.sensitive_data
        instruction_context = {
            "instruction" : ["Initial Step no instructions right now",],
            "agent_response" : ["Initial Step no agent response right now",],
        }
        new_task = None
        step = 0
        failure = 0
        max_failures = 2
        last_run_results = []
        try:
            while True and failure<=max_failures:
                    try:
                        response_history : AgentHistoryList = await self.BrowserAgent.run_task(
                                        context_id=context_id,
                                        task = new_task if new_task else task,
                                        use_vision=True,
                                        sensitive_data=sensitive_data,
                                        last_result = last_run_results if last_run_results else None,
                                        next_action=None)
                        
                    except Exception as e:
                        print("error while executing agent Browser.")
                        print(e)
                        raise e
                            
                    step += 1
                    browser_response = response_history.final_result()
                    last_result = ActionResult(
                        success=response_history.is_successful(),
                        is_done= response_history.is_done(),
                        extracted_content= browser_response,
                        error = None,
                        include_in_memory= True
                    )
                    last_run_results.append(last_result)
                    instruction_context.get("agent_response").append(browser_response)
                    
                    next_action : ExeActionStruct = await self.LLMHandler.get_structured_response(
                        output_structure=ExeActionStruct,
                        prompt = VALIDATION_PROMPT,
                        user_task = state.user_task,
                        agent_response = browser_response,
                    )
                    
                    if next_action.user_task_completed:
                        print("Task is completed!!!")
                        state.results = next_action.final_response
                        print(next_action.final_response)
                        state.routes["executor"] = [END]
                        state.route_config["executor"] = RouteConfig(
                                from_node="executor",
                                conditional_nodes=[END]
                                        )
                        return state   
                    
                    else:
                        failure += 1
                        new_task = next_action.next_step
                        print(new_task)
                        continue
                        
            
        except Exception as e:
                    logger.error(
                    f"[{state.context_id}] Task execution failed: {str(e)}\n"
                    f"Traceback: {traceback.format_exc()}"
                    )
        
        state.routes["other"] = [END]
        state.route_config["other"] = RouteConfig(
        from_node="other",
        conditional_nodes=[END])
        
        return state
        # try:
            # while step <= self._max_steps and failure <= max_failures:
            #     model_response : ExeActionStruct = await self.LLMHandler.get_structured_response(
            #                 prompt= EXEPROMPT, 
            #                 output_structure= ExeActionStruct,
            #                 use_model="google",
            #                 task = task,
            #                 previous_step = instruction_context.get("instruction")[-1],
            #                 agent_response = instruction_context.get("agent_response")[-1],
            #                 )
                    
                # if model_response.user_task_completed:
                #     print("Task is completed!!!")
                #     state.results = model_response.final_response
                #     print(f"Final Response {model_response.final_response}")
                #     state.routes["executor"] = [END]
                #     state.route_config["executor"] = RouteConfig(
                #             from_node="executor",
                #             conditional_nodes=[END]
                #                     )
                #     return state   
                            
                # else:
                #     if not model_response.current_task_completed:
                #         failure += 1

                #     next_action = model_response.next_step
                #     instruction_context.get("instruction").append(next_action)
   
                #     print(f"This is the main instruction for current step : --------->{next_action}")

                # try:
                #     try:
                #         response_history : AgentHistoryList = await self.BrowserAgent.run_task(
                #                         context_id=context_id,
                #                         task = f"{task}",
                #                         use_vision=True,
                #                         sensitive_data=sensitive_data,
                #                         last_result = last_run_results if last_run_results else None,
                #                         next_action=None)
                #     except Exception as e:
                #         print("error while executing agent Browser.")
                #         print(e)
                #         raise e
                            
                #     step += 1
                #     browser_response = response_history.final_result()
                #     last_result = ActionResult(
                #         success=response_history.is_successful(),
                #         is_done= response_history.is_done(),
                #         extracted_content= browser_response,
                #         error = None,
                #         include_in_memory= True
                #     )
                #     last_run_results.append(last_result)
                #     instruction_context.get("agent_response").append(browser_response)
                #     # continue
            
                # except Exception as e:
                #     logger.error(
                #     f"[{state.context_id}] Task execution failed: {str(e)}\n"
                #     f"Traceback: {traceback.format_exc()}"
                #     )
                    # break

        #     state.routes["executor"] = [END]
        #     state.route_config["executor"] = RouteConfig(
        #             from_node="executor",
        #             conditional_nodes=[END]
        #         )
        #     return state
        # except Exception as e:
        #     raise e       
        
    async def run(self, user_task: str,context_id :str, sensitive_data : Dict =None) -> Dict[str, Any]:
        """
        Run the agent on a given query.
        
        Args:
            query: The user's query/task
            
        Returns:
            Results of the agent execution
        """
        try:
            # Prepare initial state
            initial_state = AutoAgentState(
                user_task=user_task,
                messages=[HumanMessage(content=user_task)],
                context_id=context_id,
                sensitive_data= sensitive_data
            )
            
            # Run the workflow
            try:
                final_state = await self.workflow.ainvoke(initial_state)
            except Exception as e:
                raise e
            
            print("Now closing context")
            await self.BrowserAgent.close_context(context_id=context_id)
            return final_state
        
        except Exception as e:
            logger.error(f"Error running agent: {str(e)}")
            raise e 
        
    async def close(self):
        """Close any open resources."""
        await self.http_client.aclose()

